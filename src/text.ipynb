{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c8f29d-288e-481f-a58f-8dfae2910846",
   "metadata": {},
   "source": [
    "## AI - Работа с текстом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad17eba-c805-4bea-98cd-252520df712f",
   "metadata": {},
   "source": [
    "_Код использует библиотеку Transformers, которая предоставляет доступ к предварительно обученным моделям для работы с текстом. В данном случае, код использует PyTorch для выполнения операций нейросетевого обучения и генерации текста._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc40906-658b-4851-ba94-8cc7cf9e4fbd",
   "metadata": {},
   "source": [
    "## Generative Pre-trained Transformer (GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c416bdc-c6ac-44f9-a5ac-6d3be70fa296",
   "metadata": {},
   "source": [
    "Генерация текстовых ответов на основе сообщения пользователя с использованием gpt модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a9d8e1-7d1b-49a3-bbac-cb3efa8a29e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1. gpt2\n",
      "2. gpt2-large\n",
      "\n",
      "Введите номер модели которую хотели бы использовать:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загрузка модели...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ваше сообщение:  world is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загрузка сообщения...\n",
      "Ответ:  world is far away, but we could find it. There's more to life than science fiction, even though scientists aren't sure what those stories mean. Scientists know the laws of physics more or less. They have a better idea of what the next five years are going to be like, and they're a bunch of good scientists. So people get excited about it and it's exciting to be able to say to our customers \"Well, let's go there and work with them for the next ten\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "models = [\"gpt2\", \"gpt2-large\"]\n",
    "model_indx = int(input(\"\\n\".join([f'{i+1}. {v}' for i, v in enumerate(models)]) + \"\\n\\nВведите номер модели которую хотели бы использовать: \"))\n",
    "print(\"загрузка модели...\")\n",
    "text_generation = pipeline(\"text-generation\", model=models[model_indx-1])\n",
    "# set_seed(50)\n",
    "\n",
    "user_message = input(\"Ваше сообщение: \")\n",
    "print(\"загрузка сообщения...\")\n",
    "generated_text= text_generation(user_message, max_length=100)[0]\n",
    "answer = generated_text[\"generated_text\"]\n",
    "print(\"Ответ: \", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced4976-23c8-4333-ba94-5ab3b232171e",
   "metadata": {},
   "source": [
    "## Masked Language Modeling (MLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53263f-cfd0-4065-a62d-3580f74d4675",
   "metadata": {},
   "source": [
    "В тексте __\"Paris is the [MASK] of France.\"__ определенное слово заменено на [MASK], и код использует модель BERT для предсказания, какое слово могло бы находиться на месте [MASK]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ac87b2-4f88-4ac5-8efd-6e1b95ef9ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для предложения \"Paris is the [MASK] of France.\" подходят следующие маски:\n",
      "токен: capital, вероятность: 0.996937\n",
      "токен: heart, вероятность: 0.000591\n",
      "токен: center, вероятность: 0.000438\n",
      "токен: centre, вероятность: 0.000338\n",
      "токен: city, вероятность: 0.00027\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "text = \"Paris is the [MASK] of France.\"\n",
    "result = unmasker(text)\n",
    "\n",
    "print(f\"Для предложения \\\"{text}\\\" подходят следующие маски:\\n\")\n",
    "print(\"\\n\".join(map(lambda item: f\"токен: {item['token_str']}, вероятность: {round(item['score'], 6)}\", result)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdf06b-9113-4893-bb18-c31c8bd09496",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe6e95-e464-469a-a75a-5903b84fcbc0",
   "metadata": {},
   "source": [
    "Анализ тональности текста с помощью предварительно обученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891d8b35-4457-43be-ad01-40707fc6b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ваше сообщение:  i love you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваше сообщение POSITIVE с вероятностью 0.999866 %\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_analysis = pipeline('sentiment-analysis')\n",
    "user_message = input(\"Ваше сообщение: \")\n",
    "result = sentiment_analysis(user_message)[0]\n",
    "\n",
    "print(f\"Ваше сообщение {result['label']} с вероятностью {round(result['score'], 6)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb82a7-5cac-4960-81e8-36c496528032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
